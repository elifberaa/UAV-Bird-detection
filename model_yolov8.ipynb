{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqreFUQOC6a8",
        "outputId": "a80c4982-ccd7-492c-a626-142236d4d2b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME =  os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_mOvgXwDCjI",
        "outputId": "8ce17b8e-7629-491c-8e57-255f3a5f7ac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vs08ay41DCoJ",
        "outputId": "b399446c-7dbc-4401-f020-02010cb31edb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.98 ðŸš€ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (8 CPUs, 51.0 GB RAM, 32.6/235.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!pip install opencv-python ultralytics\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I599MwT_DCsl"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "RfqB4GPmVEfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I0r3EnEDNJp",
        "outputId": "887d0927-21e3-40c5-82ac-1d74be291309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt to 'yolov8x.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131M/131M [00:00<00:00, 407MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.98 ðŸš€ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=/content/drive/MyDrive/yolo_model_egitimi/train test val/data (2).yaml, epochs=30, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=True, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=10, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 102MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
            "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
            "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
            "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
            "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
            "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
            "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
            "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
            "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
            " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
            " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 22        [15, 18, 21]  1   8719894  ultralytics.nn.modules.head.Detect           [2, [320, 640, 640]]          \n",
            "Model summary: 365 layers, 68,154,534 parameters, 68,154,518 gradients, 258.1 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.1.conv.weight'\n",
            "Freezing layer 'model.1.bn.weight'\n",
            "Freezing layer 'model.1.bn.bias'\n",
            "Freezing layer 'model.2.cv1.conv.weight'\n",
            "Freezing layer 'model.2.cv1.bn.weight'\n",
            "Freezing layer 'model.2.cv1.bn.bias'\n",
            "Freezing layer 'model.2.cv2.conv.weight'\n",
            "Freezing layer 'model.2.cv2.bn.weight'\n",
            "Freezing layer 'model.2.cv2.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.2.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.2.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.2.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.2.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.2.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.2.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.2.m.2.cv1.conv.weight'\n",
            "Freezing layer 'model.2.m.2.cv1.bn.weight'\n",
            "Freezing layer 'model.2.m.2.cv1.bn.bias'\n",
            "Freezing layer 'model.2.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.2.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.2.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.3.conv.weight'\n",
            "Freezing layer 'model.3.bn.weight'\n",
            "Freezing layer 'model.3.bn.bias'\n",
            "Freezing layer 'model.4.cv1.conv.weight'\n",
            "Freezing layer 'model.4.cv1.bn.weight'\n",
            "Freezing layer 'model.4.cv1.bn.bias'\n",
            "Freezing layer 'model.4.cv2.conv.weight'\n",
            "Freezing layer 'model.4.cv2.bn.weight'\n",
            "Freezing layer 'model.4.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.2.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.2.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.2.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.3.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.3.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.3.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.3.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.3.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.3.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.4.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.4.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.4.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.4.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.4.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.4.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.5.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.5.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.5.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.5.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.5.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.5.cv2.bn.bias'\n",
            "Freezing layer 'model.5.conv.weight'\n",
            "Freezing layer 'model.5.bn.weight'\n",
            "Freezing layer 'model.5.bn.bias'\n",
            "Freezing layer 'model.6.cv1.conv.weight'\n",
            "Freezing layer 'model.6.cv1.bn.weight'\n",
            "Freezing layer 'model.6.cv1.bn.bias'\n",
            "Freezing layer 'model.6.cv2.conv.weight'\n",
            "Freezing layer 'model.6.cv2.bn.weight'\n",
            "Freezing layer 'model.6.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.2.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.2.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.2.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.3.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.3.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.3.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.3.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.3.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.3.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.4.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.4.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.4.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.4.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.4.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.4.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.5.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.5.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.5.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.5.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.5.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.5.cv2.bn.bias'\n",
            "Freezing layer 'model.7.conv.weight'\n",
            "Freezing layer 'model.7.bn.weight'\n",
            "Freezing layer 'model.7.bn.bias'\n",
            "Freezing layer 'model.8.cv1.conv.weight'\n",
            "Freezing layer 'model.8.cv1.bn.weight'\n",
            "Freezing layer 'model.8.cv1.bn.bias'\n",
            "Freezing layer 'model.8.cv2.conv.weight'\n",
            "Freezing layer 'model.8.cv2.bn.weight'\n",
            "Freezing layer 'model.8.cv2.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.8.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.8.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.8.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.8.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.8.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.8.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.8.m.2.cv1.conv.weight'\n",
            "Freezing layer 'model.8.m.2.cv1.bn.weight'\n",
            "Freezing layer 'model.8.m.2.cv1.bn.bias'\n",
            "Freezing layer 'model.8.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.8.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.8.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.9.cv1.conv.weight'\n",
            "Freezing layer 'model.9.cv1.bn.weight'\n",
            "Freezing layer 'model.9.cv1.bn.bias'\n",
            "Freezing layer 'model.9.cv2.conv.weight'\n",
            "Freezing layer 'model.9.cv2.bn.weight'\n",
            "Freezing layer 'model.9.cv2.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:00<00:00, 367MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/yolo_model_egitimi/train test val/train.cache... 3663 images, 4 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3667/3667 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 213, len(boxes) = 4218. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (3.2GB RAM): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3667/3667 [04:21<00:00, 14.03it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/yolo_model_egitimi/train test val/val.cache... 780 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 780/780 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 41, len(boxes) = 923. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.7GB RAM): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 780/780 [00:08<00:00, 95.77it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/30      5.17G      1.443      1.929      1.672         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:55<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:20<00:00,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.879      0.798      0.885      0.626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/30         5G      1.198      1.035      1.445          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:53<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.911      0.827      0.906      0.642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/30      5.02G      1.058     0.8472      1.324          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:53<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.899       0.86       0.92      0.667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/30      5.02G     0.9384     0.6933      1.233         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923        0.9      0.878      0.923      0.678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/30       5.4G      0.864     0.6113      1.179          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.877      0.863      0.917      0.672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/30      5.03G     0.7991     0.5606      1.139          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.911      0.871      0.925      0.679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/30      5.41G     0.7403     0.5156      1.105          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.909      0.886      0.927      0.673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/30      5.01G     0.7184     0.4948      1.095          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.933      0.869      0.928      0.685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/30       5.4G     0.6788     0.4665       1.06          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923       0.93      0.878       0.93      0.691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/30      5.03G     0.6468      0.439      1.047         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.909      0.885      0.932      0.691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/30      5.01G     0.6099     0.4148      1.036          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.934      0.887      0.936      0.705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/30      5.01G      0.611     0.4192      1.026         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.929      0.883      0.936      0.704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/30      5.39G      0.588     0.4046      1.017         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.938      0.886      0.944      0.714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/30      5.02G     0.5695     0.3932      1.009          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.923      0.893       0.94      0.698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/30      5.39G     0.5629      0.383       1.01         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.928      0.881      0.933      0.706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/30      5.03G     0.5542     0.3764      1.003          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.908      0.906      0.937      0.702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/30      5.01G     0.5308     0.3621     0.9891          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.931      0.892      0.936      0.709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/30      5.02G     0.5279     0.3619     0.9864          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.935      0.878      0.938      0.717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/30         5G     0.5109     0.3515      0.979         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.919      0.898      0.936      0.707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/30      4.97G     0.5118     0.3468     0.9773         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.906      0.904       0.94      0.718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/30         5G     0.7056     0.3928      1.161          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.935      0.888      0.937      0.723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/30      5.01G     0.6727     0.3686      1.127          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.938      0.882      0.945      0.735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/30         5G     0.6556     0.3557      1.112          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.939      0.901      0.947      0.741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/30      5.03G      0.636     0.3439      1.102          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.931      0.904       0.95      0.744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/30       5.4G     0.6236     0.3326      1.098          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.931      0.914      0.954      0.748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/30      5.02G     0.6102     0.3236      1.086          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.936      0.897      0.947      0.747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/30      5.41G     0.6028     0.3092      1.079          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.932      0.909       0.95       0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/30         5G     0.5991     0.3044      1.075          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.945       0.91      0.954      0.753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/30         5G     0.5861     0.2978      1.068          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.928      0.921      0.954      0.754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/30      5.02G     0.5765     0.2896      1.066          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230/230 [02:52<00:00,  1.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:18<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923      0.934      0.918      0.953      0.756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "30 epochs completed in 1.610 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 136.7MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 136.7MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.98 ðŸš€ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 268 layers, 68,125,494 parameters, 0 gradients, 257.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:41<00:00,  1.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        780        923       0.94       0.93      0.961      0.763\n",
            "                  Bird        452        578      0.941      0.939      0.971       0.77\n",
            "                   UAV        327        345       0.94      0.922      0.951      0.755\n",
            "Speed: 0.1ms preprocess, 49.0ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#model = YOLO('yolov8n.pt')\n",
        "#results = model.train(data=\"/content/drive/MyDrive/model_eÄŸitimi/data.yaml\", epochs=20)\n",
        "\n",
        "#model = YOLO('yolov9e.pt')\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# YOLOv8 modelini yÃ¼kle (yolov8x daha bÃ¼yÃ¼k bir modeldir, daha kÃ¼Ã§Ã¼k modeller kullanÄ±yorsanÄ±z yolov8n, yolov8s gibi versiyonlar deneyin)\n",
        "model = YOLO('yolov8x.pt')\n",
        "\n",
        "# Model eÄŸitimi\n",
        "results = model.train(\n",
        "    data=\"/content/drive/MyDrive/yolo_model_egitimi/train test val/data (2).yaml\",  # Data dosyasÄ± yolu\n",
        "    epochs=30,        # Epoch sayÄ±sÄ±nÄ± artÄ±rarak daha uzun eÄŸitim sÃ¼resi\n",
        "    imgsz=640,         # GÃ¶rÃ¼ntÃ¼ boyutu\n",
        "    batch=16,          # Batch boyutunu artÄ±rarak daha fazla veri ile eÄŸitim\n",
        "    workers=8,         # Ä°ÅŸ parÃ§acÄ±ÄŸÄ± sayÄ±sÄ±\n",
        "    amp=True,          # Automatic Mixed Precision (AMP) kullanarak eÄŸitim hÄ±zÄ±nÄ± artÄ±rma\n",
        "    cache=True,        # Verileri belleÄŸe alarak eÄŸitim sÃ¼resini hÄ±zlandÄ±rma\n",
        "    optimizer='SGD',   # SGD optimizasyon algoritmasÄ± (Adam yerine)\n",
        "    lr0=0.001,         # BaÅŸlangÄ±Ã§ Ã¶ÄŸrenme oranÄ± (kÃ¼Ã§Ã¼k deÄŸerler daha stabil eÄŸitim saÄŸlar)\n",
        "    lrf=0.01,          # Ã–ÄŸrenme oranÄ± faktÃ¶rÃ¼\n",
        "    weight_decay=0.0005,  # AÄŸÄ±rlÄ±k bozumu, overfitting'i engellemek iÃ§in\n",
        "    #autoanchor=True,   # Anchor box'larÄ± otomatik olarak ayarlama\n",
        "    augment=True,      # Veri artÄ±rma iÅŸlemi\n",
        "    #early_stopping=True,  # Erken durdurma kullanarak eÄŸitim performansÄ±nÄ± izleme\n",
        "    patience=50,       # Erken durdurma iÃ§in sabÄ±r sÃ¼resi\n",
        "    freeze=10,         # Ä°lk 10 katmanÄ± dondurma (pretrained modeli kullanÄ±rken)\n",
        "    save=True,         # Modeli kaydet\n",
        "    plots=True         # EÄŸitim sÃ¼resince grafik Ã§izdirme\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gf2JCc7wttc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WjRLNboHGAT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}